from openai import OpenAI
import streamlit as st

# è®¾ç½®é¡µé¢çš„å®½åº¦å’ŒåŸºç¡€æ ·å¼
st.set_page_config(page_title="ChatMaster", layout="wide")



# è®¾ç½®APIå¯†é’¥
client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# æ·»åŠ ä¾§è¾¹æ ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©äº¤æµæ¨¡å¼
with st.sidebar:
    st.header("è®¾ç½®")
    # æ¨¡å‹é€‰æ‹©å™¨
    model_choice = st.selectbox(
        "é€‰æ‹©æ¨¡å‹",
        options=["gpt-3.5-turbo", "gpt-4"],
        index=0
    )
    # è¯­è¨€é€‰æ‹©å™¨
    language_choice = st.selectbox(
        "é€‰æ‹©è¯­è¨€",
        options=["ä¸­æ–‡", "English"],
        index=1  # é»˜è®¤é€‰æ‹©English
    )
    # å¢åŠ ç•Œé¢åˆ‡æ¢é€‰é¡¹
    interaction_mode = st.selectbox(
        "é€‰æ‹©äº¤æµæ¨¡å¼",
        options=["å£è¯­äº¤æµ", "æ–‡å­—å¯¹è¯"],
        index=1  # é»˜è®¤æ–‡å­—å¯¹è¯
    )

    st.write("é€‰æ‹©ä¸åŒçš„æ¨¡å¼ä»¥è·å¾—ä¸ªæ€§åŒ–ä½“éªŒã€‚")

# æ ¹æ®ç”¨æˆ·é€‰æ‹©çš„äº¤æµæ¨¡å¼æ¸²æŸ“ä¸åŒçš„ç•Œé¢
if interaction_mode == "å£è¯­äº¤æµ":
    # æ˜¾ç¤ºæ•°å­—äººå›¾ç‰‡ï¼Œå‡†å¤‡ç”¨äºå£è¯­äº¤æµ
    st.image("./assert/image/æ•°å­—äºº.png", caption="å‡†å¤‡å¼€å§‹å£è¯­äº¤æµ", width=500)
    
    # è¿™é‡Œä½ å¯ä»¥é›†æˆä¸€ä¸ªè¯­éŸ³è¾“å…¥åŠŸèƒ½
    st.write("è¯·ä½¿ç”¨è¯­éŸ³å¯¹è¯åŠŸèƒ½ï¼ˆæœªæ¥å¯æ·»åŠ è¯­éŸ³è¯†åˆ«æ¥å£ï¼‰ã€‚")

elif interaction_mode == "æ–‡å­—å¯¹è¯":
    # è®¾ç½®è‡ªå®šä¹‰æ ‡é¢˜
    st.title("ğŸ¦œğŸ”— ChatMaster - ä½ çš„ä¸“å±è‹±æ–‡å¤–æ•™")

    # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
    if "messages" not in st.session_state:
        st.session_state.messages = []

    # æ˜¾ç¤ºå†å²å¯¹è¯
    for message in st.session_state.messages:
        with st.chat_message(message["role"]):
            st.markdown(message["content"])

    # ç”¨æˆ·è¾“å…¥æ¡†
    if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜"):
        # å¦‚æœé€‰æ‹©äº†ä¸­æ–‡ï¼Œæ·»åŠ æç¤ºè®©æ¨¡å‹å›ç­”ä¸­æ–‡
        if language_choice == "ä¸­æ–‡":
            prompt = f"è¯·ç”¨ä¸­æ–‡å›ç­”: {prompt}"

        # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
        st.session_state.messages.append({"role": "user", "content": prompt})

        # å®æ—¶æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
        with st.chat_message("user"):
            st.markdown(prompt)

        # æ·»åŠ åŠ è½½çŠ¶æ€ï¼Œæ˜¾ç¤ºâ€œAIæ­£åœ¨æ€è€ƒä¸­...â€
        with st.chat_message("assistant"):
            assistant_placeholder = st.empty()

            # å‡†å¤‡æ¶ˆæ¯è®°å½•
            messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

            # è°ƒç”¨OpenAI APIï¼Œæµå¼è·å–å›ç­”
            stream = client.chat.completions.create(
                model=model_choice,  # åŠ¨æ€é€‰æ‹©æ¨¡å‹
                messages=messages,
                temperature=0.5,
                stream=True
            )

            # å®æ—¶æ¥æ”¶å¹¶æµå¼æ˜¾ç¤ºAIçš„å›ç­”
            full_response = ""
            for chunk in stream:
                content = chunk['choices'][0]['delta'].get('content', '')
                full_response += content
                assistant_placeholder.markdown(full_response)

        # ä¿å­˜AIçš„å®Œæ•´å›ç­”
        st.session_state.messages.append({"role": "assistant", "content": full_response})

# æ·»åŠ è¿›é˜¶åŠŸèƒ½ï¼šæ˜¾ç¤ºè¯·æ±‚è®¡æ•°ä¸TokenèŠ±è´¹
with st.sidebar:
    if st.session_state.messages:
        total_tokens = sum(len(msg['content']) for msg in st.session_state.messages)
        st.write(f"å·²ä½¿ç”¨Tokenæ•°é‡: {total_tokens}")


# from openai import OpenAI
# import streamlit as st

# # è®¾ç½®é¡µé¢çš„å®½åº¦å’ŒåŸºç¡€æ ·å¼
# st.set_page_config(page_title="ChatMaster", layout="wide")

# # è®¾ç½®è‡ªå®šä¹‰æ ‡é¢˜
# st.title("ğŸ¦œğŸ”— ChatMaster - ä½ çš„ä¸“å±è‹±æ–‡å¤–æ•™")

# # æ·»åŠ ä¾§è¾¹æ ï¼Œç”¨æˆ·å¯ä»¥é€‰æ‹©æ¨¡å‹å’Œè¯­è¨€
# with st.sidebar:
#     st.header("è®¾ç½®")
#     # åœ¨ä¾§è¾¹æ æ·»åŠ æ•°å­—äººå›¾ç‰‡
#     st.image("./assert/image/æ•°å­—äºº.png", caption="AI å¤–æ•™", use_column_width=True)
    
#     # æ¨¡å‹é€‰æ‹©å™¨å’Œè¯­è¨€é€‰æ‹©å™¨ç­‰æ§ä»¶
#     model_choice = st.selectbox(
#         "é€‰æ‹©æ¨¡å‹",
#         options=["gpt-3.5-turbo", "gpt-4"],
#         index=0
#     )
#     language_choice = st.selectbox(
#         "é€‰æ‹©è¯­è¨€",
#         options=["ä¸­æ–‡", "English"],
#         index=1
#     )
#     st.write("é€‰æ‹©ä¸åŒçš„æ¨¡å‹å’Œè¯­è¨€ä»¥è·å¾—ä¸ªæ€§åŒ–ä½“éªŒã€‚")

# # è®¾ç½®APIå¯†é’¥
# client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# # åˆå§‹åŒ–ä¼šè¯çŠ¶æ€
# if "messages" not in st.session_state:
#     st.session_state.messages = []

# # æ˜¾ç¤ºå†å²å¯¹è¯
# for message in st.session_state.messages:
#     with st.chat_message(message["role"]):
#         st.markdown(message["content"])

# # ç”¨æˆ·è¾“å…¥æ¡†
# if prompt := st.chat_input("è¯·è¾“å…¥ä½ çš„é—®é¢˜"):
#     # å¦‚æœé€‰æ‹©äº†ä¸­æ–‡ï¼Œæ·»åŠ æç¤ºè®©æ¨¡å‹å›ç­”ä¸­æ–‡
#     if language_choice == "ä¸­æ–‡":
#         prompt = f"è¯·ç”¨ä¸­æ–‡å›ç­”: {prompt}"
    
#     # å°†ç”¨æˆ·è¾“å…¥æ·»åŠ åˆ°ä¼šè¯çŠ¶æ€
#     st.session_state.messages.append({"role": "user", "content": prompt})
    
#     # å®æ—¶æ˜¾ç¤ºç”¨æˆ·è¾“å…¥
#     with st.chat_message("user"):
#         st.markdown(prompt)
    
#     # æ·»åŠ åŠ è½½çŠ¶æ€ï¼Œæ˜¾ç¤ºâ€œAIæ­£åœ¨æ€è€ƒä¸­...â€
#     with st.chat_message("assistant"):
#         assistant_placeholder = st.empty()

#         # å‡†å¤‡æ¶ˆæ¯è®°å½•
#         messages = [{"role": m["role"], "content": m["content"]} for m in st.session_state.messages]

#         # è°ƒç”¨OpenAI APIï¼Œæµå¼è·å–å›ç­”
#         stream = client.chat.completions.create(
#             model=model_choice,  # åŠ¨æ€é€‰æ‹©æ¨¡å‹
#             messages=messages,
#             temperature=0.5,
#             stream=True
#         )

#         # å®æ—¶æ¥æ”¶å¹¶æµå¼æ˜¾ç¤ºAIçš„å›ç­”
#         full_response = ""
#         for chunk in stream:
#             content = chunk['choices'][0]['delta'].get('content', '')
#             full_response += content
#             assistant_placeholder.markdown(full_response)  # åŠ¨æ€æ›´æ–°ç•Œé¢

#     # ä¿å­˜AIçš„å®Œæ•´å›ç­”
#     st.session_state.messages.append({"role": "assistant", "content": full_response})

# # æ·»åŠ è¿›é˜¶åŠŸèƒ½ï¼šæ˜¾ç¤ºè¯·æ±‚è®¡æ•°ä¸TokenèŠ±è´¹
# with st.sidebar:
#     if st.session_state.messages:
#         total_tokens = sum(len(msg['content']) for msg in st.session_state.messages)
#         st.write(f"å·²ä½¿ç”¨Tokenæ•°é‡: {total_tokens}")



# # from openai import OpenAI
# # import streamlit as st

# # st.title("ğŸ¦œğŸ”— ChatMaster")

# # client = OpenAI(api_key=st.secrets["OPENAI_API_KEY"])

# # if "openai_model" not in st.session_state:
# #     st.session_state["openai_model"] = "gpt-3.5-turbo"

# # if "messages" not in st.session_state:
# #     st.session_state.messages = []

# # for message in st.session_state.messages:
# #     with st.chat_message(message["role"]):
# #         st.markdown(message["content"])

# # if prompt := st.chat_input("What is up?"):
# #     st.session_state.messages.append({"role": "user", "content": prompt})
# #     with st.chat_message("user"):
# #         st.markdown(prompt)

# #     with st.chat_message("assistant"):
# #         stream = client.chat.completions.create(
# #             model=st.session_state["openai_model"],
# #             messages=[
# #                 {"role": m["role"], "content": m["content"]}
# #                 for m in st.session_state.messages
# #             ],
# #             stream=True,
# #         )
# #         response = st.write_stream(stream)
# #     st.session_state.messages.append({"role": "assistant", "content": response})